{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":82611,"databundleVersionId":9553358,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm import tqdm\nfrom itertools import product\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.impute import SimpleImputer\n\nimport warnings\nwarnings.filterwarnings('ignore', message='not allowed')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-26T07:55:23.644318Z","iopub.execute_input":"2024-11-26T07:55:23.645142Z","iopub.status.idle":"2024-11-26T07:55:26.299373Z","shell.execute_reply.started":"2024-11-26T07:55:23.645094Z","shell.execute_reply":"2024-11-26T07:55:26.298476Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Define the hour and minute ranges for constructing feature column names\nhours = range(0, 6, 1)\nminutes = range(0, 60, 5)\n\ntarget_col = \"bg+1-00\"  # Target column name for prediction\ngroup_col = \"p_num\"  # Column name for grouping (e.g., participant number)\ndate_col = \"time\"  # Column name for time data\n\n# We only need the last 12 time intervals (1 hour)\nbg_cols = [f\"bg-{i}-{j:02d}\" for i, j in product(hours, minutes)][:12]\ninsu_cols = [f\"insulin-{i}-{j:02d}\" for i, j in product(hours, minutes)][:12]\ncarb_cols = [f\"carbs-{i}-{j:02d}\" for i, j in product(hours, minutes)][:12]\nhr_cols = [f\"hr-{i}-{j:02d}\" for i, j in product(hours, minutes)][:12]\nstep_cols = [f\"steps-{i}-{j:02d}\" for i, j in product(hours, minutes)][:12]\ncals_cols = [f\"cals-{i}-{j:02d}\" for i, j in product(hours, minutes)][:12]\n\nfeature_cols = bg_cols + insu_cols + carb_cols + hr_cols + step_cols + cals_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T07:55:26.300979Z","iopub.execute_input":"2024-11-26T07:55:26.301354Z","iopub.status.idle":"2024-11-26T07:55:26.309286Z","shell.execute_reply.started":"2024-11-26T07:55:26.301326Z","shell.execute_reply":"2024-11-26T07:55:26.308296Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df_train = pd.read_csv(\n    '/kaggle/input/brist1d/train.csv', \n    index_col='id', \n    parse_dates=['time'],\n)\n\ndf_test = pd.read_csv(\n    '/kaggle/input/brist1d/test.csv', \n    index_col='id', \n    parse_dates=['time'],\n)\n\ndf_subm = pd.read_csv(\n    \"/kaggle/input/brist1d/sample_submission.csv\",\n    index_col='id',\n)\n\n# Some frameworks may not handle column names with special characters like colons properly\ndf_train.columns = df_train.columns.str.replace(':', '-')\ndf_test.columns = df_test.columns.str.replace(':', '-')\n\n\nseed = 43  #\nThr_NAN = 49\n\nfor colset in [bg_cols, insu_cols, carb_cols, hr_cols, step_cols, cals_cols]:\n    df_train[colset] = (\n        df_train[colset]\n        .interpolate(axis=1)\n        .fillna(method=\"bfill\", axis=1)\n        .fillna(method=\"ffill\", axis=1)\n    )\n    df_test[colset] = (\n        df_test[colset]\n        .interpolate(axis=1)\n        .fillna(method=\"bfill\", axis=1)\n        .fillna(method=\"ffill\", axis=1)\n    )\nmask = df_train[feature_cols].isna().sum(axis=1) <= Thr_NAN\n# Apply the mask to filter the rows\ndf_train = df_train[mask]\n\n\nimputer = SimpleImputer()  \n\ndf_train[feature_cols] = imputer.fit_transform(df_train[feature_cols])\ndf_test[feature_cols] = imputer.transform(df_test[feature_cols])\n\n\ndf_train[\"sin_hour\"] = np.sin(np.pi * df_train[date_col].dt.hour / 12)\ndf_train[\"cos_hour\"] = np.cos(np.pi * df_train[date_col].dt.hour / 12)\n\ndf_test[\"sin_hour\"] = np.sin(np.pi * df_test[date_col].dt.hour / 12)\ndf_test[\"cos_hour\"] = np.cos(np.pi * df_test[date_col].dt.hour / 12)\n\nfeature_cols.extend([\"sin_hour\", \"cos_hour\"])\n\n\ngrouped_features = []\n\n# Iterate through each set of related columns (e.g., blood glucose, insulin, etc.)\nfor colset in [bg_cols, insu_cols, carb_cols, hr_cols, step_cols, cals_cols]:\n    group_idxs = [idx for idx, col in enumerate(feature_cols) if col in colset]\n    grouped_features.append(group_idxs)\n\n\ndf_train_final = df_train[feature_cols]\ngroups = df_train[group_col]\n\ny_target = df_train[[target_col]]\n\ndf_test_final = df_test[feature_cols]\n\nX = df_train_final\ny = y_target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T07:55:26.310559Z","iopub.execute_input":"2024-11-26T07:55:26.310860Z","iopub.status.idle":"2024-11-26T07:55:51.336111Z","shell.execute_reply.started":"2024-11-26T07:55:26.310834Z","shell.execute_reply":"2024-11-26T07:55:51.335357Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/583805281.py:1: DtypeWarning: Columns (435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_train = pd.read_csv(\n/tmp/ipykernel_30/583805281.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  df_train = pd.read_csv(\n/tmp/ipykernel_30/583805281.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  df_test = pd.read_csv(\n/tmp/ipykernel_30/583805281.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_train[colset]\n/tmp/ipykernel_30/583805281.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_test[colset]\n/tmp/ipykernel_30/583805281.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_train[colset]\n/tmp/ipykernel_30/583805281.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_test[colset]\n/tmp/ipykernel_30/583805281.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_train[colset]\n/tmp/ipykernel_30/583805281.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_test[colset]\n/tmp/ipykernel_30/583805281.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_train[colset]\n/tmp/ipykernel_30/583805281.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_test[colset]\n/tmp/ipykernel_30/583805281.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_train[colset]\n/tmp/ipykernel_30/583805281.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_test[colset]\n/tmp/ipykernel_30/583805281.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_train[colset]\n/tmp/ipykernel_30/583805281.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df_test[colset]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scaling \nscaler = StandardScaler()\ntrain_X = scaler.fit_transform(train_X)\ntest_X = scaler.transform(test_X)\ndf_test_final = scaler.transform(df_test_final)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T07:55:51.338206Z","iopub.execute_input":"2024-11-26T07:55:51.339040Z","iopub.status.idle":"2024-11-26T07:55:51.707792Z","shell.execute_reply.started":"2024-11-26T07:55:51.339000Z","shell.execute_reply":"2024-11-26T07:55:51.707048Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"%%time\nimport lightgbm as lgb\nfrom lightgbm import early_stopping\n\ntrain_y = np.array(train_y)\ntest_y = np.array(test_y)\n# Create the LightGBM dataset\ntrain_data = lgb.Dataset(train_X, label=train_y)\ntest_data = lgb.Dataset(test_X, label=test_y)\n\n# Set initial parameters\nparams = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    \"device\": \"gpu\",  # Use GPU\n    'feature_fraction': 0.9\n}\n\n\n# Train the model\ngbm = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets=[train_data, test_data],\n    callbacks=[early_stopping(stopping_rounds=10)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T07:55:51.708823Z","iopub.execute_input":"2024-11-26T07:55:51.709164Z","iopub.status.idle":"2024-11-26T07:56:09.472297Z","shell.execute_reply.started":"2024-11-26T07:55:51.709128Z","shell.execute_reply":"2024-11-26T07:56:09.471434Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:335: UserWarning: Converting column-vector to 1d array\n  _log_warning('Converting column-vector to 1d array')\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17392\n[LightGBM] [Info] Number of data points in the train set: 140392, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n","output_type":"stream"},{"name":"stderr","text":"1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (8.57 MB) transferred to GPU in 0.009131 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.263568\nTraining until validation scores don't improve for 10 rounds\nDid not meet early stopping. Best iteration is:\n[1000]\ttraining's rmse: 1.60227\tvalid_1's rmse: 1.8127\nCPU times: user 45.1 s, sys: 1.1 s, total: 46.2 s\nWall time: 17.8 s\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error\n\npred = gbm.predict(test_X)\nmae = mean_absolute_error(test_y, pred)\nprint(f\"MAE:{mae}\")\nrmse = np.sqrt(mean_squared_error(test_y, pred))\nprint(f\"RMSE: {rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T07:56:09.473183Z","iopub.execute_input":"2024-11-26T07:56:09.473786Z","iopub.status.idle":"2024-11-26T07:56:10.437517Z","shell.execute_reply.started":"2024-11-26T07:56:09.473752Z","shell.execute_reply":"2024-11-26T07:56:10.436205Z"}},"outputs":[{"name":"stdout","text":"MAE:1.3389883925348074\nRMSE: 1.8127\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'num_leaves': [70, 80],\n    'learning_rate': [0.01, 0.001],\n    'n_estimators': [1000, 3500, 4500]\n}\n\n# Create the LightGBM estimator\nestimator = lgb.LGBMRegressor(device=\"gpu\")\n\ntrain_y \n# Perform grid search\ngbm_cv = GridSearchCV(estimator, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\ngbm_cv.fit(train_X, train_y)\n\n# Best parameters\nprint('Best cross-validation score:', -gbm_cv.best_score_)\nprint('Best parameters found by grid search are:', gbm_cv.best_params_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T07:56:10.438838Z","iopub.execute_input":"2024-11-26T07:56:10.439105Z","iopub.status.idle":"2024-11-26T09:05:09.331853Z","shell.execute_reply.started":"2024-11-26T07:56:10.439076Z","shell.execute_reply":"2024-11-26T09:05:09.330682Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.048609 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.025736 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.023367 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.037771 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.022298 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.017946 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.044367 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.024405 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.017459 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.021246 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.039559 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.021775 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019148 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.025690 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.020885 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.017338 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.026588 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.020749 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.022883 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019498 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019070 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.017839 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.023804 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.024036 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.020882 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.021598 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.022513 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.017139 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.099052 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.077077 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.037656 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019737 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.018827 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019550 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.023614 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.018666 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.017166 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.021817 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019000 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.020589 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.022114 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.018230 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17392\n[LightGBM] [Info] Number of data points in the train set: 140392, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (8.57 MB) transferred to GPU in 0.007954 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.263568\nBest cross-validation score: 3.0782059577970977\nBest parameters found by grid search are: {'learning_rate': 0.01, 'n_estimators': 4500, 'num_leaves': 80}\nCPU times: user 2min 34s, sys: 4.87 s, total: 2min 39s\nWall time: 1h 8min 58s\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"best_params = gbm_cv.best_params_\n\n# Update the parameters\nparams.update(best_params)\n\n# Train the final model\ngbm = lgb.train(\n    params,\n    train_data,\n    num_boost_round=1000,\n    valid_sets=[train_data, test_data],\n    callbacks=[early_stopping(stopping_rounds=10)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T09:05:09.334922Z","iopub.execute_input":"2024-11-26T09:05:09.335197Z","iopub.status.idle":"2024-11-26T09:06:25.980599Z","shell.execute_reply.started":"2024-11-26T09:05:09.335167Z","shell.execute_reply":"2024-11-26T09:06:25.979753Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17392\n[LightGBM] [Info] Number of data points in the train set: 140392, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (8.57 MB) transferred to GPU in 0.008911 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.263568\nTraining until validation scores don't improve for 10 rounds\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","output_type":"stream"},{"name":"stdout","text":"Did not meet early stopping. Best iteration is:\n[4500]\ttraining's rmse: 1.3431\tvalid_1's rmse: 1.73708\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"pred = gbm.predict(test_X)\nmae = mean_absolute_error(test_y, pred)\nprint(f\"MAE:{mae}\")\nrmse = np.sqrt(mean_squared_error(test_y, pred))\nprint(f\"RMSE: {rmse:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T09:06:25.981607Z","iopub.execute_input":"2024-11-26T09:06:25.981918Z","iopub.status.idle":"2024-11-26T09:06:30.760339Z","shell.execute_reply.started":"2024-11-26T09:06:25.981887Z","shell.execute_reply":"2024-11-26T09:06:30.759100Z"}},"outputs":[{"name":"stdout","text":"MAE:1.2802394442916867\nRMSE: 1.7371\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"Results = gbm.predict(df_test_final)\n\ndf_subm['bg+1:00'] = Results\n\ndf_subm.to_csv('Submission_LGB_Fine-tuning.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T09:06:30.761248Z","iopub.execute_input":"2024-11-26T09:06:30.761559Z","iopub.status.idle":"2024-11-26T09:06:31.369057Z","shell.execute_reply.started":"2024-11-26T09:06:30.761527Z","shell.execute_reply":"2024-11-26T09:06:31.368232Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.027740 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.022245 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.022847 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.018979 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019979 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.014599 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019447 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019182 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.018482 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17401\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.020642 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.021043 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17377\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.034928 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17370\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.025383 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17373\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.016915 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.255092\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.027698 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.257620\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.018638 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.262814\n[LightGBM] [Info] Number of data points in the train set: 112313, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.019297 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.272823\n[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 17364\n[LightGBM] [Info] Number of data points in the train set: 112314, number of used features: 74\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 62 dense feature groups (6.86 MB) transferred to GPU in 0.018729 secs. 1 sparse feature groups\n[LightGBM] [Info] Start training from score 8.269489\n","output_type":"stream"}],"execution_count":10}]}